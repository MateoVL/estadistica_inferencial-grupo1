---
title: "EP09-respuesta-equipo-9"
date: "2026-01-07"
output: html_document
---


# EP 9

Un estudio recolectó medidas anatómicas de 247 hombres y 260 mujeres (Heinz et al., 2003). El estudio incluyó nueve mediciones del esqueleto (ocho diámetros y una profundidad de hueso a hueso) y doce mediciones de grosor (circunferencias) que incluyen el tejido. La siguiente tabla detalla las variables registradas en este estudio:

Biacromial.diameter	Diámetro biacromial (a la altura de los hombros)	cm
Biiliac.diameter	Diámetro biiliaco (a la altura de la pelvis)	cm
Bitrochanteric.diameter	Diámetro bitrocantéreo (a la altura de las caderas)	cm
Chest.depth	Profundidad del pecho (entre la espina y el esternón a la altura de los pezones)	cm
Chest.diameter	Diámetro del pecho (a la altura de los pezones)	cm
Elbows.diameter	Suma de los diámetros de los codos	cm
Wrists.diameter	Suma de los diámetros de las muñecas	cm
Knees.diameter	Suma de los diámetros de las rodillas	cm
Ankles.diameter	Suma de los diámetros de los tobillos	cm
Shoulder.Girth	Grosor de los hombros sobre los músculos deltoides	cm
Chest.Girth	Grosor del pecho, sobre tejido mamario en mujeres y a la altura de los pezones en varones	cm
Waist.Girth	Grosor a la altura de la cintura	cm
Navel.Girth	Grosor a la altura del ombligo	cm
Hip.Girth	Grosor a la altura de las caderas	cm
Thigh.Girth	Grosor promedio de ambos muslos bajo el pliegue del glúteo	cm
Bicep.Girth	Grosor promedio de ambos bíceps, brazos flectados	cm
Forearm.Girth	Grosor promedio de ambos antebrazos, brazos extendidos palmas hacia arriba	cm
Knee.Girth	Grosor promedio de ambas rodillas, posición levemente flectada, medición arriba de la rótula	cm
Calf.Maximum.Girth	Grosor promedio de la parte más ancha de ambas pantorrillas	cm
Ankle.Minimum.Girth	Grosor promedio de la parte más delgada de ambos tobillos	cm
Wrist.Minimum.Girth	Grosor promedio de la parte más delgada de ambas muñecas	cm
Age	Edad	Años
Weight	Peso	Kg
Height	Estatura	cm
Gender	Género	1: hombre
0: mujer


Pasos:
Definir la semilla a utilizar, que corresponde a los últimos cuatro dígitos del RUN (sin considerar el dígito verificador) del integrante de menor edad del equipo.
Seleccionar una muestra aleatoria de 100 mujeres (si la semilla es un número par) o 100 hombres (si la semilla es impar), y separar 70 casos para trabajar en la construcción de modelos y 30 para su evaluación en datos no vistos.
Seleccionar de forma aleatoria ocho posibles variables predictoras.
Seleccionar, de las otras variables, una que el equipo considere que podría ser útil para predecir la variable Peso (sin considerar la estatura), justificando bien esta selección.
Usando el entorno R y paquetes estándares1, construir un modelo de regresión lineal simple con el predictor seleccionado en el paso anterior.
Usando herramientas estándares1 para la exploración de modelos del entorno R, buscar entre dos y cinco predictores de entre las variables seleccionadas al azar en el punto 3, para agregar al modelo de regresión lineal simple obtenido en el paso 5.
Evaluar la bondad de ajuste (incluyendo el análisis de casos atípicos y casos influyentes) y la generalidad (condiciones para RLM) de los modelos y “arreglarlos” en caso de que presenten algún problema.
Evaluar el poder predictivo del modelo con los datos no utilizados para construirlo.

```{r}
library(car) # Necesario para diagnósticos (vif, ncvTest, durbinWatson)
library(dplyr)
library(leaps)

set.seed(3413)

datos <- read.csv2("EP09 Datos.csv")
muestra <- datos[datos$Gender == 1, ][sample(sum(datos$Gender == 1), 100), ]

indices_train <- sample(100, size = 0.7 * 100)

train <- muestra[indices_train, ]
test  <- muestra[-indices_train, ]

respuesta <- "Weight"
candidatos <- setdiff(colnames(train), c(respuesta, "Gender", "ID"))
predictores <- sample(candidatos, 8, replace = FALSE)
predictores

```
De las otras variables, elegimos "Chest.diameter", que describe el diámetro del pecho a la altura de los pezones. Elegimos esta variable por que existen estudios que indican que la grasa en hombres tiende a acumularse en esta zona implicando un mayor volumen y masa. 

```{r}
# Ajustamos el modelo usando la función lm() como base.
modelo_simple <- lm(Weight ~Chest.diameter, data = train)

# Mostramos el resumen para ver coeficientes y R2
summary(modelo_simple)

```

Se usará una estrategia de selección hacia adelante con step(), ya que las instrucciones indican "Elegir entre 2 a 5 variables predictoras", y lo que buscamos es explorar los datos.
Como el objetivo es agregar variables a un modelo base ya existente, la selección hacia adelante es una buena estrategia, ya que a partir de un modelo nulo se van escogiendo las variables más prometedoras para agregarlas al modelo. El algoritmo evalúa de forma iterativa cuál o cuales son las que mejoran más el modelo base.
Este método utiliza el AIC para guiar la búsqueda, lo que es fundamental porque el AIC no solo reduce el error sino que penaliza la complejidad del modelo, siguiendo así el principio de parsimonia.

```{r}
# Definimos el modelo "completo" posible (nuestro modelo simple + las 8 variables aleatorias)
formula_scope <- as.formula(paste("Weight ~ Chest.diameter +", paste(predictores, collapse = " + ")))

# Usamos step() con dirección "forward" para agregar variables que mejoren el AIC.
# Limitamos steps a 5 para no agregar demasiadas, aunque el criterio AIC parará antes si es necesario.
#
modelo_rlm <- step(modelo_simple, 
                   scope = list(lower = modelo_simple, upper = formula_scope), 
                   direction = "forward", 
                   trace = 1,
                   steps = 5) # trace=1 muestra el proceso paso a paso

# Vemos el modelo resultante
summary(modelo_rlm)

```

De los resultados, se puede apreciar que se construyó un modelo con 5 variables predictoras distintas a Chest.diameter, sin embargo, esta misnma no significativa al agregar las demas variables(Chest.diameter (p=0.107)).

Debido a esto, siguiendo el procedimiento de eliminación hacia atrás  y respetando el nivel de significancia alpha < 0,05, se procede a eliminar la variable Chest.diameter (p=0.107) utilizando la función update(), ya que no aporta significativamente al ajuste del modelo.

```{r}
#Usamos update() para quitar SOLO la variable con p-value alto (Knee.Girth)
modelo_refinado <- update(modelo_rlm, . ~ . - Chest.diameter)

#Mostramos el nuevo resumen con las 5 variables restantes
summary(modelo_refinado)

```
R^2 ajustado = 0.8852. Este es el valor más importante en la RLM porque penaliza la complejidad. Nos indica que el modelo con esas variables es capaz de explicar el 88,52% de la variabilidad del peso de las personas en la muestra de entrenamiento. Es un valor alto, lo que sugiere que las variables seleccionadas son determinantes fuertes del peso.

Además, el estadístico F (98.7) y el p-value (< 2.2e-16). El valor p es extremadamente pequeño, lo que confirma que rechazamos la hipótesis nula global, por lo que existe evidencia de que al menos uno de los predictores ayuda a predecir el peso, y que el modelo es mejor que usar simplemente el promedio del peso.


Ahora veridicaremos la confiabilidad del modelo:

1. La variable de salida (peso) es una variable cuantitativa y continua, ya que mide una magnitud fisica.

2. Los predictores son cuantitativos, ya que son mediciones fisicas de un objeto real.

3. Los predictores no son constantes.

4. Cada predictor debe estar relacionado linealmente con la respuesta.


```{r}
# Linealidad
# Gráficos de residuos vs predictores
residualPlots(modelo_refinado)
# Busca líneas rojas curvas. Si son rectas (o casi rectas), la linealidad se cumple.
# Si hay curvas muy marcadas, falta linealidad.

```
Identifcamos que la variable Calf.Maximum.Girth falló la prueba individual p < 0.05 y mostró una línea curva en el gráfico.
Como una de las condiciones es que cada predictor debe estar relacionado linealmente con la respuesta, Si observamos una curvatura, debemos detenernos a estudiar por que ocurre esto. Para esto nos apoyaremos en influencePlot.

```{r}
influencePlot(modelo_refinado, id.method="identify", main="Gráfico de Influencia")
```

Usamos influencePlot para investigar si existen observaciones influyentes. En este caso, encontramos 3 casos críticos en la tabla y gráfico, y uno muy cercano al límite.

Caso 241: Residuo Estudentizado = -3.39.
Caso 215: Residuo Estudentizado = -2.71.
Caso 124: Residuo Estudentizado =  2.17
Caso 222: Residuo Estudentizado =  1.99

El criterio para los residuos estudentizados, es que  valores por encima de +2 o por debajo de -2 son sospechosos y potencialmente problemáticos.
La curvatura que vimos en el gráfico de ResidualPlots puede no ser real, sino una consecuencia de estos casos atípicos. Estos individuos tienen un peso real mucho más bajo de lo que el modelo predice, y el modelo los intenta explicar curvandose.


```{r}
# 1. Definimos los NOMBRES de los casos a eliminar (como texto o identificadores)
nombres_outliers <- c("241", "215", "124")

# 2. Filtramos usando los nombres de fila (rownames)
# Le decimos a R: "Quédate con las filas cuyo nombre NO esté en la lista de outliers"
train_limpio <- train[ !rownames(train) %in% nombres_outliers, ]

# 3. Ahora sí, actualizamos el modelo
modelo_arreglado <- update(modelo_refinado, data = train_limpio)

# 4. Verificar nuevamente
residualPlots(modelo_arreglado)
```
Se procedió a eliminar del conjunto de entrenamiento las observaciones 241, 215 y 124.
Estas observaciones presentaban residuos estudentizados con valores absolutos superiores a 2 y menores a -2, Además,la presencia de observaciones sobreinfluyentes afectan las precisión del modelo. Podemos apreciar que la eliminación de estos casos atípicos corrigió exitosamente el problema de linealidad detectado previamente en la variable.
la prueba de curvatura para esta variable arrojaba un valor significativo p = 0.038. Tras la rectificación, el nuevo valor p es 0.0912. Al ser 0.091 > 0.05, ya no hay evidencia estadística suficiente para rechazar la hipótesis de linealidad.
Al "arreglar" el modelo eliminando los 3 casos anteriores, el modelo final (modelo_arreglado) cumple ahora con todos los supuestos exigidos para una Regresión Lineal Múltiple confiable.


5. La distibucion de los residuos debe ser cercana a la normal centrada en cero.

6. La variabilidad de los residuos debe ser aproximadamente constante (homocedasticidad)

```{r}
# Homocedasticidad (Varianza constante de los errores)
ncvTest(modelo_refinado)
# CRITERIO: El p-value debe ser > 0.05.
# Si es menor, la varianza de los errores cambia (error variable), lo cual es malo.
```
El p-value es 0.35795, lo que es mayor que el nivel de significancia alpha = 0.05, por lo que no existe evidencia suficiente para rechazar la hipótesis de homocedasticidad. Por lo tanto, se asume que el modelo cumple con la condición.


7. Los residuos deben ser independientes entre sí.

```{r}
# Independencia de los residuos
durbinWatsonTest(modelo_refinado)
# CRITERIO: El p-value debe ser > 0.05 para "no rechazar" la independencia.
```
Como el p-value es 0.916, y este valor es mucho mayor que el nivel de significancia alpha = 0.05, no existe evidencia suficiente para rechazar la independencia. 
Además el estadístico D-W tiene un valor de 1.970302. Un valor cercano a 2 indica ausencia total de autocorrelación.


8. No debe existir multicolinealidad.

```{r}
# A) Multicolinealidad (VIF)
vif(modelo_refinado)
# CRITERIO:
# - VIF > 5: Preocupante.
# - VIF > 10: Severo (Debes eliminar esa variable).
```
Como los valores máximos rondan el rondan 1 y 2.1, los predictores son lo suficientemente independientes entre sí para que el modelo sea estable.


A continuación, se pondrá a prueba el modelo con los datos no utilizados para construirlo para evaluar su poder predictivo.

```{r}
# 1. Generar predicciones para los 30 casos nuevos
# Usamos el modelo ya arreglado (sin los outliers) y el conjunto 'test'
predicciones_test <- predict(modelo_arreglado, newdata = test)

# 2. Calcular el error real (Diferencia entre Peso Real y Predicho)
# Nota: Asumo que la columna de peso en 'test' se llama 'weight' igual que en el modelo.
error_test <- test$Weight - predicciones_test

# 3. Calcular métricas de desempeño
# RMSE (Raíz del Error Cuadrático Medio): Penaliza más los errores grandes.
rmse_test <- sqrt(mean(error_test^2))

# MAE (Error Absoluto Medio): El error promedio simple.
mae_test <- mean(abs(error_test))

# 4. Obtener el error del entrenamiento para comparar (Sigma)
error_entrenamiento <- summary(modelo_arreglado)$sigma

# 5. Mostrar resultados comparativos
cat("=== RESULTADOS DE LA EVALUACIÓN FINAL ===\n")
cat("RMSE en Test (Datos nuevos):      ", round(rmse_test, 3), "kg\n")
cat("MAE en Test (Error promedio):     ", round(mae_test, 3), "kg\n")
cat("-----------------------------------------\n")
cat("Error en Entrenamiento (Sigma):   ", round(error_entrenamiento, 3), "kg\n")
cat("Diferencia (Test - Entrenamiento):", round(rmse_test - error_entrenamiento, 3), "kg\n")
```
Precisión en el "Mundo Real": error absoluto medio (MAE) es de 3.63 kg. Esto indica que, en promedio, el modelo construido se equivoca por unos 3.6 kilos aprox al estimar el peso de una persona desconocida. Sin embargo, considerando que el peso corporal de un adulto varía comúnmente entre 50 y 90 kg, un error promedio de 3.6 kg es bastante aceptable para un modelo lineal.

Evaluación de la generalización (RMSE vs. Sigma):

Error en Entrenamiento (Optimista): 3.389 kg.
Error en Test (Realista): 5.003 kg.

La Brecha: Existe una diferencia de 1.613 kg. El error aumentó al pasar a datos nuevos.

observamos que el Error Estándar Residual del entrenamiento (3.39 kg) es menor que el RMSE obtenido en el conjunto de prueba (5.00 kg). Esta diferencia se debe a que las métricas de ajuste sobre la muestra de construcción tienden a ser estimaciones optimistas.

Por otra parte, el incremento en el error no indica necesariamente un fallo del modelo, sino que puede ser influenciado por el efecto de la depuración de valores atípicos realizada en la fase de entrenamiento. Mientras que el entrenamiento se realizó construyendo un modelo que cumpliera todas las condiciones, y fue rectificado con la eliminación de algunos datos, la evaluación final se hizo sobre datos reales no filtrados, y solo 30 de ellos. A pesar de esto, el modelo evita errores severos, lo cual demuestra una capacidad predictiva válida para observaciones nuevas.

